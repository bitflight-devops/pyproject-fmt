---
phase: 01-core-pipeline
plan: 02
type: execute
wave: 2
depends_on: ["01-01"]
files_modified:
  - tests/test_pipeline.py
  - tests/conftest.py
autonomous: true

must_haves:
  truths:
    - "Pipeline output matches golden file byte-for-byte (TEST-02, TEST-06)"
    - "Pipeline is idempotent: two runs produce identical output (PIPE-04)"
    - "Every key, value, and table in before.toml survives the pipeline (TEST-03)"
    - "Table ordering in output matches golden file exactly (TEST-04)"
    - "Key ordering within each table matches golden file exactly (TEST-04)"
    - "Every comment in before.toml appears at its correct position in after.toml (TEST-05)"
  artifacts:
    - path: "tests/test_pipeline.py"
      provides: "Pipeline test suite: golden file comparison, data loss detection, ordering verification, comment fidelity"
      contains: "test_golden_file_match"
    - path: "tests/conftest.py"
      provides: "Test fixtures for before/after TOML content and fixture paths"
      contains: "before_toml"
  key_links:
    - from: "tests/test_pipeline.py"
      to: "src/pyproject_fmt/pipeline.py"
      via: "import format_pyproject"
      pattern: "from pyproject_fmt\\.pipeline import"
    - from: "tests/test_pipeline.py"
      to: "tests/fixtures/after.toml"
      via: "golden file comparison"
      pattern: "after\\.toml"
    - from: "tests/test_pipeline.py"
      to: "tests/fixtures/before.toml"
      via: "pipeline input"
      pattern: "before\\.toml"
---

<objective>
Create the complete test suite for the pipeline: golden file byte-comparison, idempotency, structural data loss detection, table/key ordering verification, and comment position fidelity checks.

Purpose: These tests prove the pipeline is correct and guard against regressions. Any formatting drift, data loss, or ordering corruption is caught immediately.
Output: test_pipeline.py with 6+ test functions covering all TEST-* requirements, updated conftest.py with fixture helpers.
</objective>

<execution_context>
@/home/ubuntulinuxqa2/.claude/get-shit-done/workflows/execute-plan.md
@/home/ubuntulinuxqa2/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-core-pipeline/01-RESEARCH.md
@.planning/phases/01-core-pipeline/01-01-SUMMARY.md

# Source files
@src/pyproject_fmt/pipeline.py
@src/pyproject_fmt/config.py

# Fixtures
@tests/fixtures/before.toml
@tests/fixtures/after.toml
@tests/conftest.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Golden file comparison, idempotency, and data loss detection tests</name>
  <files>
    tests/test_pipeline.py
    tests/conftest.py
  </files>
  <action>
Update `tests/conftest.py` to add fixture helpers. PRESERVE existing fixtures (sample_data). Add:
- `fixtures_dir` fixture: returns `Path(__file__).parent / "fixtures"`
- `before_toml` fixture: reads and returns `fixtures_dir / "before.toml"` text content
- `after_toml` fixture: reads and returns `fixtures_dir / "after.toml"` text content (the golden file)

Create `tests/test_pipeline.py` with these test functions:

**TEST-01 + TEST-02 + TEST-06: Golden file comparison**
```python
def test_golden_file_match(before_toml, after_toml):
    """Pipeline output must match golden file byte-for-byte."""
    result = format_pyproject(before_toml)
    assert result == after_toml, (
        "Pipeline output does not match golden file.\n"
        + "\n".join(difflib.unified_diff(
            after_toml.splitlines(keepends=True),
            result.splitlines(keepends=True),
            fromfile="expected (after.toml)",
            tofile="actual (pipeline output)",
        ))
    )
```

**PIPE-04: Idempotency**
```python
def test_idempotency(before_toml):
    """Running pipeline twice must produce identical output."""
    first = format_pyproject(before_toml)
    second = format_pyproject(first)
    assert first == second, "Pipeline is not idempotent"
```

**TEST-03: Data loss detection - keys and values**
```python
def test_no_data_loss_keys(before_toml):
    """Every key present in input must survive the pipeline."""
    import tomllib
    before_data = tomllib.loads(before_toml)
    result = format_pyproject(before_toml)
    after_data = tomllib.loads(result)
    # Recursively collect all leaf key paths from before_data
    # Verify each exists in after_data with the same value
    # Use a recursive helper that builds dotted key paths
```

Implement the recursive key comparison helper:
- Flatten both dicts to `{"section.key": value}` form
- For each key in before, assert it exists in after
- For each key in before, assert the VALUE matches
- Report which keys are missing or have wrong values

**TEST-03: Data loss detection - tables**
```python
def test_no_data_loss_tables(before_toml):
    """Every table present in input must survive the pipeline."""
    import tomllib
    before_data = tomllib.loads(before_toml)
    result = format_pyproject(before_toml)
    after_data = tomllib.loads(result)
    # Collect all table paths from before_data
    # Verify each exists in after_data
```

**PIPE-05: Input validation**
```python
def test_invalid_toml_raises():
    """Invalid TOML input must raise TOMLDecodeError."""
    import tomllib
    with pytest.raises(tomllib.TOMLDecodeError):
        format_pyproject("[invalid\ntoml = ")
```

Import `format_pyproject` from `pyproject_fmt.pipeline`. Import `difflib`, `tomllib`, `pytest`, `pathlib.Path`.
  </action>
  <verify>
Run: `cd /home/ubuntulinuxqa2/repos/pyproject-fmt && uv run pytest tests/test_pipeline.py -v` -- all tests must pass.
Run: `cd /home/ubuntulinuxqa2/repos/pyproject-fmt && uv run pytest tests/test_pyproject_fmt.py -v` -- existing tests must still pass (no regressions).
  </verify>
  <done>
test_pipeline.py contains: test_golden_file_match, test_idempotency, test_no_data_loss_keys, test_no_data_loss_tables, test_invalid_toml_raises. All pass. Existing tests still pass. conftest.py updated with fixture helpers without breaking existing fixtures.
  </done>
</task>

<task type="auto">
  <name>Task 2: Table/key ordering verification and comment fidelity tests</name>
  <files>
    tests/test_pipeline.py
  </files>
  <action>
Add the following tests to `tests/test_pipeline.py`:

**TEST-04: Table ordering verification**
```python
def test_table_ordering_matches_golden(before_toml, after_toml):
    """Table order in pipeline output must match golden file exactly."""
    result = format_pyproject(before_toml)
    # Extract table headers from both golden and result using regex
    # Pattern: lines matching r'^\[{1,2}[^\]]+\]{1,2}' (captures [table] and [[array.of.tables]])
    import re
    table_pattern = re.compile(r'^\[{1,2}([^\]]+)\]{1,2}', re.MULTILINE)
    golden_tables = table_pattern.findall(after_toml)
    result_tables = table_pattern.findall(result)
    assert result_tables == golden_tables, (
        f"Table ordering mismatch.\n"
        f"Expected: {golden_tables}\n"
        f"Actual: {result_tables}"
    )
```

**TEST-04: Key ordering within tables**
```python
def test_key_ordering_within_tables(before_toml, after_toml):
    """Key order within each table must match golden file exactly."""
    result = format_pyproject(before_toml)
    # Parse both golden and result into ordered key sequences per table
    # For each table section, extract keys in order
    # Compare key sequences table-by-table
    # Use a helper that splits TOML text by table headers and extracts
    # key names (lines matching r'^(\w[\w-]*)\s*=') within each section
```

Implement the helper function that:
1. Splits TOML text into sections by `[table]` headers
2. For each section, extracts key names in order (regex: `r'^([\w][\w.-]*)\s*='` with MULTILINE)
3. Returns `dict[str, list[str]]` mapping table name to ordered key list
4. Compares table-by-table between golden and result

**TEST-05: Comment fidelity**
```python
def test_comment_preservation(before_toml):
    """Every comment in input must appear in pipeline output."""
    result = format_pyproject(before_toml)
    import re
    # Extract all comments from before_toml
    # Comments are lines starting with # (block comments) or containing # after a value (inline)
    comment_pattern = re.compile(r'#\s*(.+)')
    before_comments = set(comment_pattern.findall(before_toml))
    after_comments = set(comment_pattern.findall(result))
    missing = before_comments - after_comments
    assert not missing, (
        f"Comments lost during pipeline:\n"
        + "\n".join(f"  - # {c}" for c in sorted(missing))
    )
```

**TEST-05: Comment position fidelity**
```python
def test_comment_positions_match_golden(after_toml):
    """Comment positions in pipeline output must match golden file."""
    from pyproject_fmt.pipeline import format_pyproject
    # Run pipeline on golden file (should be identity)
    result = format_pyproject(after_toml)
    # Extract (line_number, comment_text) pairs from both
    # Since golden is a fixed point, they must be identical
    # This is already covered by byte-for-byte comparison, but we add
    # explicit comment position checking for diagnostic clarity
    golden_comments = [
        (i, line) for i, line in enumerate(after_toml.splitlines())
        if '#' in line
    ]
    result_comments = [
        (i, line) for i, line in enumerate(result.splitlines())
        if '#' in line
    ]
    assert golden_comments == result_comments, (
        "Comment positions shifted during pipeline re-run on golden file"
    )
```

**TEST-01: Golden file exists as a real artifact**
```python
def test_golden_file_exists(fixtures_dir):
    """Golden file must exist as a first-class test artifact."""
    golden = fixtures_dir / "after.toml"
    assert golden.exists(), "Golden file after.toml does not exist"
    assert golden.stat().st_size > 0, "Golden file is empty"
    # Verify it's valid TOML
    import tomllib
    tomllib.loads(golden.read_text())
```

After adding all tests, run the linter on the test file: `uv run ruff check tests/test_pipeline.py --fix` to clean up any style issues.
  </action>
  <verify>
Run: `cd /home/ubuntulinuxqa2/repos/pyproject-fmt && uv run pytest tests/test_pipeline.py -v` -- ALL tests must pass, including the new ordering and comment tests.
Run: `cd /home/ubuntulinuxqa2/repos/pyproject-fmt && uv run pytest -v` -- full test suite must pass.
Run: `cd /home/ubuntulinuxqa2/repos/pyproject-fmt && uv run ruff check tests/test_pipeline.py` -- no lint errors.
  </verify>
  <done>
test_pipeline.py contains all TEST-* requirement tests: golden file existence (TEST-01), golden file byte-comparison (TEST-02, TEST-06), data loss detection for keys/values/tables (TEST-03), table ordering verification (TEST-04), key ordering within tables (TEST-04), comment preservation (TEST-05), comment position fidelity (TEST-05), idempotency (PIPE-04), and input validation (PIPE-05). All tests pass. Full test suite passes with no regressions.
  </done>
</task>

</tasks>

<verification>
After all tasks complete:
1. `uv run pytest tests/test_pipeline.py -v` -- all tests pass
2. `uv run pytest -v` -- full test suite passes (no regressions from existing tests)
3. `uv run ruff check tests/` -- no lint errors in test files
4. Test count: At minimum 9 new tests (golden_file_exists, golden_file_match, idempotency, no_data_loss_keys, no_data_loss_tables, invalid_toml_raises, table_ordering, key_ordering, comment_preservation, comment_positions)
5. Each TEST-* requirement has at least one corresponding test function
</verification>

<success_criteria>
- test_pipeline.py exists with 9+ test functions
- All tests pass when run with pytest
- TEST-01: test_golden_file_exists confirms after.toml is real and valid
- TEST-02 + TEST-06: test_golden_file_match confirms byte-for-byte match
- TEST-03: test_no_data_loss_keys + test_no_data_loss_tables confirm no data loss
- TEST-04: test_table_ordering + test_key_ordering confirm exact ordering
- TEST-05: test_comment_preservation + test_comment_positions confirm comment fidelity
- PIPE-04: test_idempotency confirms running twice produces same output
- PIPE-05: test_invalid_toml_raises confirms validation catches bad input
- Existing tests in test_pyproject_fmt.py still pass
</success_criteria>

<output>
After completion, create `.planning/phases/01-core-pipeline/01-02-SUMMARY.md`
</output>
